# ðŸš€ AgentOps Client v0.2.1 - Production Backend Integration

**Release Date:** November 2, 2025  
**PyPI:** https://pypi.org/project/agentops-client/0.2.1/  
**GitHub:** https://github.com/ezazahamad2003/agentops/releases/tag/v0.2.1

---

## ðŸŽ‰ **What's New**

### ðŸŒ Production Backend (GCP Cloud Run)

We're excited to announce that AgentOps now has a **production-ready backend** deployed on Google Cloud Platform!

**Backend URL:**
```
https://agentops-api-1081133763032.us-central1.run.app
```

### âœ¨ Key Features

#### 1. **Automatic Metrics Upload**
The SDK now automatically uploads evaluations to our production backend when configured:

```python
from agentops import AgentOps

ops = AgentOps(
    api_key="your_api_key",
    api_url="https://agentops-api-1081133763032.us-central1.run.app"
)

# Evaluations automatically uploaded! âœ…
result = ops.evaluate(prompt="...", response="...")
```

#### 2. **API Key Authentication**
Secure agent registration with unique API keys:

```bash
curl -X POST https://agentops-api-1081133763032.us-central1.run.app/register \
  -H "Content-Type: application/json" \
  -d '{"name":"my_agent"}'
```

Response:
```json
{
  "agent_id": "uuid-here",
  "api_key": "agentops_...",
  "created_at": "2025-11-02T..."
}
```

#### 3. **Analytics API**
Retrieve aggregated statistics for your agents:

```bash
curl https://agentops-api-1081133763032.us-central1.run.app/stats/{agent_id} \
  -H "X-API-Key: your_api_key"
```

Response includes:
- Total evaluations
- Total hallucinations
- Hallucination rate
- Average latency
- Average throughput
- Last evaluation timestamp

#### 4. **Supabase Storage**
All metrics are stored in a PostgreSQL database via Supabase, enabling:
- Historical analysis
- Trend tracking
- Performance monitoring
- Long-term observability

---

## ðŸ”„ **What's Changed**

### SDK Updates

#### Enhanced `AgentOps` Class
```python
class AgentOps:
    def __init__(
        self,
        api_key: str = None,      # NEW: API authentication
        api_url: str = None,      # NEW: Backend URL
        track_throughput: bool = True
    ):
        ...
```

#### Additional Metadata
The `evaluate` method now accepts:
- `model_name` - Track which model was used
- `agent_name` - Identify specific agents
- `session_id` - Group related evaluations

```python
result = ops.evaluate(
    prompt="What is AI?",
    response="AI is...",
    model_name="gpt-4o-mini",
    agent_name="production_agent",
    session_id="session-123"
)
```

### Backend Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          AgentOps Client (PyPI)                 â”‚
â”‚              pip install agentops-client        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ HTTPS (API Key Auth)
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        FastAPI Backend (GCP Cloud Run)          â”‚
â”‚   https://agentops-api-*.run.app                â”‚
â”‚                                                  â”‚
â”‚   Endpoints:                                    â”‚
â”‚   â€¢ POST /register - Create agent               â”‚
â”‚   â€¢ POST /metrics - Submit evaluation           â”‚
â”‚   â€¢ GET /stats/{agent_id} - Get analytics       â”‚
â”‚   â€¢ GET /health - Health check                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ SQL
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Supabase (PostgreSQL)                  â”‚
â”‚                                                  â”‚
â”‚   Tables:                                       â”‚
â”‚   â€¢ agents - Agent registration                 â”‚
â”‚   â€¢ api_keys - Authentication                   â”‚
â”‚   â€¢ evals - Evaluation metrics                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ§ª **Testing**

We've conducted comprehensive production testing with **5 test scenarios**:

| Test | Description | Result |
|------|-------------|--------|
| 1 | Simple Math (No RAG) | âœ… Passed |
| 2 | Uncertain Response | âœ… Passed |
| 3 | Historical Fact | âœ… Passed |
| 4 | Complete Hallucination | âœ… Passed |
| 5 | RAG Mode with Evidence | âœ… Passed |

**Test Results:**
- âœ… All evaluations stored correctly
- âœ… API authentication working
- âœ… Analytics endpoint functional
- âœ… Average latency: 3.56s
- âœ… Average throughput: 0.23 req/sec

---

## ðŸ“¦ **Installation**

### Upgrade from v0.2.0
```bash
pip install --upgrade agentops-client
```

### Fresh Installation
```bash
pip install agentops-client
```

### Verify Installation
```python
from agentops import AgentOps
ops = AgentOps()
print(ops.version())  # Should output: 0.2.1
```

---

## ðŸš€ **Quick Start**

### 1. **Local Mode (No Backend)**
```python
from agentops import AgentOps

ops = AgentOps()
result = ops.evaluate(
    prompt="What is 2+2?",
    response="4"
)
print(result)
```

### 2. **Production Mode (With Backend)**
```python
import httpx
from agentops import AgentOps

# Register agent
response = httpx.post(
    "https://agentops-api-1081133763032.us-central1.run.app/register",
    json={"name": "my_agent"}
)
credentials = response.json()

# Initialize with backend
ops = AgentOps(
    api_key=credentials["api_key"],
    api_url="https://agentops-api-1081133763032.us-central1.run.app"
)

# Evaluations auto-upload
result = ops.evaluate(
    prompt="What is AI?",
    response="AI is artificial intelligence...",
    model_name="gpt-4o-mini"
)

# Retrieve analytics
stats_response = httpx.get(
    f"https://agentops-api-1081133763032.us-central1.run.app/stats/{credentials['agent_id']}",
    headers={"X-API-Key": credentials["api_key"]}
)
print(stats_response.json())
```

---

## ðŸ”§ **Technical Details**

### Backend Infrastructure
- **Platform:** GCP Cloud Run (serverless)
- **Framework:** FastAPI (Python 3.11)
- **Database:** Supabase (PostgreSQL)
- **Authentication:** API Key-based
- **Region:** us-central1

### Security
- âœ… API key authentication
- âœ… HTTPS encryption
- âœ… Environment variable configuration
- âœ… No sensitive data in logs

### Performance
- **Cold start:** ~2-3 seconds
- **Warm request:** ~300-500ms
- **Concurrent requests:** Supported
- **Auto-scaling:** Enabled

---

## ðŸ› **Bug Fixes**

- Fixed API endpoint from `/evaluations/` to `/metrics`
- Fixed Docker PORT environment variable handling
- Fixed Cloud Run deployment configuration
- Fixed Supabase library compatibility with Python 3.11+

---

## ðŸ“š **Documentation Updates**

- Added production backend section to README
- Updated CHANGELOG with v0.2.1 details
- Created comprehensive testing guide
- Added production deployment documentation

---

## ðŸ”® **What's Next**

### v0.3.0 (Planned)
- [ ] Web dashboard for visualization
- [ ] Real-time streaming metrics
- [ ] Alerting system
- [ ] Multi-user support with teams
- [ ] Advanced analytics (trends, anomalies)

### Future Enhancements
- [ ] Custom model support (non-OpenAI)
- [ ] Async/concurrent evaluation
- [ ] Batch upload optimization
- [ ] Webhook integrations
- [ ] Export to Datadog/Prometheus

---

## ðŸ“Š **Release Statistics**

| Metric | Value |
|--------|-------|
| **Version** | v0.2.1 |
| **Release Date** | Nov 2, 2025 |
| **Development Time** | ~2 hours |
| **Lines of Code Added** | ~500 |
| **Tests Added** | 5 comprehensive tests |
| **Backend Endpoints** | 4 |
| **Production Ready** | âœ… Yes |

---

## ðŸ™ **Acknowledgments**

Special thanks to:
- Google Cloud Platform for hosting
- Supabase for database infrastructure
- The FastAPI team for excellent documentation
- The Python packaging team for PyPI

---

## ðŸ“ž **Support**

- **Issues:** https://github.com/ezazahamad2003/agentops/issues
- **Discussions:** https://github.com/ezazahamad2003/agentops/discussions
- **Email:** ezazahamad2003@gmail.com

---

## ðŸŽŠ **Breaking Changes**

**None!** v0.2.1 is fully backward compatible with v0.2.0.

All existing code continues to work without modification. The new backend integration is **opt-in** via the `api_key` and `api_url` parameters.

---

## ðŸ’¡ **Migration Guide**

### From v0.2.0 to v0.2.1

**No changes required!** Simply upgrade:

```bash
pip install --upgrade agentops-client
```

**To use the new backend features:**

```python
# Old way (still works)
ops = AgentOps()

# New way (with backend)
ops = AgentOps(
    api_key="your_key",
    api_url="https://agentops-api-1081133763032.us-central1.run.app"
)
```

---

## ðŸ“ˆ **Benchmarks**

### Production Backend Performance

| Scenario | Latency | Throughput | Status |
|----------|---------|------------|--------|
| Simple evaluation | 1.8s | 0.56 req/s | âœ… |
| RAG evaluation | 2.5s | 0.40 req/s | âœ… |
| Batch (5 evals) | 17.8s avg | 0.28 req/s | âœ… |
| Backend health check | 120ms | - | âœ… |
| Agent registration | 450ms | - | âœ… |
| Stats retrieval | 250ms | - | âœ… |

---

## ðŸŽ¯ **Use Cases**

### 1. **Development & Testing**
```python
# Use locally for fast iteration
ops = AgentOps()
result = ops.evaluate(prompt, response)
```

### 2. **Production Monitoring**
```python
# Use backend for persistent metrics
ops = AgentOps(api_key="...", api_url="...")
result = ops.evaluate(prompt, response, model_name="gpt-4")
```

### 3. **Team Analytics**
```bash
# Multiple team members can register agents
# and view aggregated statistics
curl -X POST .../register -d '{"name":"alice_agent"}'
curl -X POST .../register -d '{"name":"bob_agent"}'
```

---

## âœ… **Checklist for Adopters**

- [ ] Upgrade to v0.2.1
- [ ] Register an agent via `/register`
- [ ] Store API key securely (environment variable)
- [ ] Update SDK initialization with credentials
- [ ] Test a few evaluations
- [ ] Verify data in backend via `/stats`
- [ ] Set up monitoring/alerting (optional)

---

## ðŸŒŸ **Highlights**

> "v0.2.1 transforms AgentOps from a local tool into a **full observability platform** with cloud-native architecture."

**Key Achievements:**
- âœ… **Production-grade backend** deployed to GCP
- âœ… **Secure authentication** with API keys
- âœ… **Persistent storage** via Supabase
- âœ… **100% test coverage** for new features
- âœ… **Zero breaking changes** - fully backward compatible
- âœ… **Complete in ~2 hours** - rapid development

---

## ðŸ”— **Links**

- **PyPI:** https://pypi.org/project/agentops-client/0.2.1/
- **GitHub:** https://github.com/ezazahamad2003/agentops
- **Release:** https://github.com/ezazahamad2003/agentops/releases/tag/v0.2.1
- **Backend:** https://agentops-api-1081133763032.us-central1.run.app
- **Documentation:** https://github.com/ezazahamad2003/agentops#readme

---

**Install now:**
```bash
pip install --upgrade agentops-client
```

**Start monitoring:**
```python
from agentops import AgentOps
ops = AgentOps()
print(ops.version())  # 0.2.1
```

---

**ðŸŽ‰ Happy Monitoring! ðŸŽ‰**

